{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0656f-2232-4260-b6d2-0ca584c63fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# First, import dependencies.\n",
    "import numpy as np\n",
    "import time, os, sys\n",
    "from cellpose import models, core\n",
    "\n",
    "# This checks to see if you have set up your GPU properly.\n",
    "# CPU performance is a lot slower, but not a problem if you are only processing a few images.\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "# for plotting \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7b10d-af6b-4b24-a7fb-6cd798feaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['/home/kcutler/DataDrive/DeLTA/delta/assets/trainingsets/2D/training/segmentation_set/img/Sample000005.png',\n",
    "         '/home/kcutler/DataDrive/DeLTA/tests/data/movie_2D_tif/Position01Channel01Frame000008.tif']\n",
    "files = files+['/home/kcutler/DataDrive/delta/delta/assets/trainingsets/2D/training/segmentation_set/img/Sample000033.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a777c7-0523-49ae-a4d9-f0fe640d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import io, transforms \n",
    "imgs = [io.imread(f) for f in files]\n",
    "\n",
    "# print some infor about the images \n",
    "for i in imgs:\n",
    "    print(i.shape)\n",
    "nimg = len(imgs)\n",
    "print(nimg)\n",
    "\n",
    "plt.figure(figsize=[4]*2) # initialize figure\n",
    "for k in range(len(imgs)):\n",
    "    img = transforms.move_min_dim(imgs[k]) # move the channel dimension last\n",
    "    if len(img.shape)>2:\n",
    "        # imgs[k] = img[:,:,1]\n",
    "        imgs[k] = np.mean(img,axis=-1)\n",
    "        \n",
    "    imgs[k] = transforms.normalize99(imgs[k],omni=True)\n",
    "    plt.subplot(1,len(files),k+1)\n",
    "    plt.imshow(imgs[k],cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f08cc6-55f8-460a-a9e9-d95de0e66c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bact_omni'\n",
    "modeldir = '/home/kcutler/DataDrive/omnipose_train/registered/models/cellpose_residual_on_style_on_concatenation_off_omni_registered_2022_01_23_16_11_17.784983_epoch_1951'\n",
    "model = [models.CellposeModel(gpu=use_GPU, model_type='bact_omni'),\n",
    "         models.CellposeModel(gpu=use_GPU, pretrained_model=modeldir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea634520-88d7-43c7-96d3-2408b5d36180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1c6bc-a969-4905-a58a-6c3d5a96e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = True\n",
    "verbose = False\n",
    "cluster = True #use clustering algorithm for Omnipose \n",
    "chans = [0,0]\n",
    "imglist = imgs[:]\n",
    "nimg = len(imgs)\n",
    "\n",
    "names = ['Omnipose','Omnipose_bit_loss']\n",
    "omni = True\n",
    "nmodel = len(names)\n",
    "masks,flows,styles,d = [[]]*nmodel,[[]]*nmodel,[[]]*nmodel,[[]]*nmodel\n",
    "\n",
    "for k in range(nmodel):\n",
    "    masks[k], flows[k], styles[k] = model[k].eval(imglist,channels=chans,rescale=None,mask_threshold=-1,flow_threshold=0,\n",
    "                                                  omni=True,cluster=cluster,resample=resample,tile=False,transparency=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499d734-abc8-4ee0-8bb3-2d1f6efa48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import plot\n",
    "import omnipose\n",
    "\n",
    "for j in range(nmodel):\n",
    "    for k in range(nimg):\n",
    "        print(names[j],model[j].pretrained_model)\n",
    "        maski = masks[j][k]\n",
    "        flowi = flows[j][k][0]\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        # im = transforms.move_min_dim(imgs[i])\n",
    "        # print(im.shape)\n",
    "        plot.show_segmentation(fig, imgs[k], maski, flowi, channels=chans, omni=True, bg_color=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a922960-0b62-4675-88a0-eca4e844ce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
