{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f308760-5b30-41ff-bd60-173ad4896565",
   "metadata": {},
   "source": [
    "## 【例8.1】Stacking集成学习示例代码。\n",
    "在scikit-learn中，可以使用StackingClassifier和StackingRegressor来实现Stacking算法。下面是一个Stacking分类的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e29be-6708-45f4-8c6e-fa4bcc1f0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成分类数据集\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=2, random_state=42)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义基学习器\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# 定义元学习器\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe98b96-eb91-4745-b156-b2e7f72aeba4",
   "metadata": {},
   "source": [
    "## 【例8.2】Bagging集成学习示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86048994-990c-4828-99eb-0ad402a67139",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成随机分类数据集\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5,\n",
    "                            n_redundant=2, random_state=42)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建Bagging分类器\n",
    "base_clf = DecisionTreeClassifier()\n",
    "clf = BaggingClassifier(base_estimator=base_clf, n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db8fde-26b6-42b6-9384-5c542d7e704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成随机分类数据集\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5,\n",
    "                            n_redundant=2, random_state=42)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建Bagging分类器\n",
    "base_clf = DecisionTreeClassifier()\n",
    "clf = BaggingClassifier(estimator=base_clf, n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadf041-98a2-4707-812f-ddb088533c66",
   "metadata": {},
   "source": [
    "## 【例8.3】AdaBoost集成学习示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf91f4a-e369-4edc-9307-150fad91c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成随机分类数据集\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5,\n",
    "                            n_redundant=2, random_state=42)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建AdaBoost分类器\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b2920-3561-4adc-8e2f-ea905a7aec41",
   "metadata": {},
   "source": [
    "## 【例8.4】Voting分类的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73e8fd-4afe-44d1-978b-29037dd0e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 加载数据\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "# 定义分类器\n",
    "clf1 = LogisticRegression(random_state=42)\n",
    "clf2 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 定义投票器\n",
    "voting_clf_hard = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2)], voting='hard')\n",
    "voting_clf_soft = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2)], voting='soft')\n",
    "\n",
    "# 训练投票器\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred_hard = voting_clf_hard.predict(X_test)\n",
    "y_pred_soft = voting_clf_soft.predict(X_test)\n",
    "\n",
    "# 输出F1指标\n",
    "print(\"Hard voting F1 score: {:.2f}\".format(f1_score(y_test, y_pred_hard, average='macro')))\n",
    "print(\"Soft voting F1 score: {:.2f}\".format(f1_score(y_test, y_pred_soft, average='macro')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23975bc6-f6cb-44d1-b62f-3601f46cb568",
   "metadata": {},
   "source": [
    "## 【例8.5】XGBClassifier集成学习示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed8e9c-76b0-4f0d-ad87-60e9edb907f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 加载数据集\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建XGB分类器\n",
    "clf = XGBClassifier()\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc792011-8fcb-4da4-a79f-3d5f73dc1245",
   "metadata": {},
   "source": [
    "## 【例8.6】Random Forest集成学习示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ddc08-9093-4351-8878-9e0ffad5c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成随机分类数据集\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5,\n",
    "                            n_redundant=2, random_state=42)\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建Random Forest分类器\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a34ad1-2200-4da2-89ba-34083ca7d4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
