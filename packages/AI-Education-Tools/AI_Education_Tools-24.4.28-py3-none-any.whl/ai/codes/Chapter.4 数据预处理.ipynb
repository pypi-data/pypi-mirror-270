{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0050e-b777-446a-9cf3-64ccebed8a67",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1317a4e7-0c4f-448d-ad98-b88887a069a8",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "source": [
    "## 【例4.1】发现缺失数据的常用方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1952f6f-1671-4830-b2fd-c997fff081b4",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A      B      C\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2   True  False  False\n",
      "3  False  False  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "       'A': [1, 2, None, 4],\n",
    "       'B': [5, None, 7, 8],\n",
    "       'C': [9, 10, 11, 12]\n",
    "   })\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467f1408-80fe-48b9-8ee5-576ee61e8630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A      B     C\n",
      "0   True   True  True\n",
      "1   True  False  True\n",
      "2  False   True  True\n",
      "3   True   True  True\n"
     ]
    }
   ],
   "source": [
    "print(df.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8564f65a-430b-475a-adfb-8c81f505c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       3 non-null      float64\n",
      " 1   B       3 non-null      float64\n",
      " 2   C       4 non-null      int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 224.0 bytes\n"
     ]
    }
   ],
   "source": [
    " df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63904041-03f1-48bf-918a-fea4b02d9d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.527525</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>1.290994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>11.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B          C\n",
       "count  3.000000  3.000000   4.000000\n",
       "mean   2.333333  6.666667  10.500000\n",
       "std    1.527525  1.527525   1.290994\n",
       "min    1.000000  5.000000   9.000000\n",
       "25%    1.500000  6.000000   9.750000\n",
       "50%    2.000000  7.000000  10.500000\n",
       "75%    3.000000  7.500000  11.250000\n",
       "max    4.000000  8.000000  12.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bef755-0160-4530-ad81-86a010c37c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpolated = df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5ee969-ca07-4866-9c7f-931a37333ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C\n",
       "0  1.0  5.0   9\n",
       "1  2.0  6.0  10\n",
       "2  3.0  7.0  11\n",
       "3  4.0  8.0  12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaaf718-5ad9-4b5a-b879-1c3df0b41d8c",
   "metadata": {},
   "source": [
    "【例4.2】以下是使用 pandas 和 scikit-learn 库进行数据清洗，包括处理缺失值、重复值和无效值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be15039b-b1db-4c7d-8f11-7f0b9518d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 创建示例数据\n",
    "data = {'姓名': ['张三', '李四', '王五', '赵六', '小明'],\n",
    "        '年龄': [23, 26, None, 24, 25],\n",
    "        '性别': ['男', '男', '女', '男', None],\n",
    "        '成绩': [90, 80, 85, 92, None]}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3119e847-9cb5-4723-b9a0-05ec0e6c8c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>姓名</th>\n",
       "      <th>年龄</th>\n",
       "      <th>性别</th>\n",
       "      <th>成绩</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>张三</td>\n",
       "      <td>23.0</td>\n",
       "      <td>男</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>李四</td>\n",
       "      <td>26.0</td>\n",
       "      <td>男</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>王五</td>\n",
       "      <td>NaN</td>\n",
       "      <td>女</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>赵六</td>\n",
       "      <td>24.0</td>\n",
       "      <td>男</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>小明</td>\n",
       "      <td>25.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   姓名    年龄    性别    成绩\n",
       "0  张三  23.0     男  90.0\n",
       "1  李四  26.0     男  80.0\n",
       "2  王五   NaN     女  85.0\n",
       "3  赵六  24.0     男  92.0\n",
       "4  小明  25.0  None   NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbdb8655-8f5b-411d-a946-c8fe273935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()\n",
    "df['年龄'].fillna(df['年龄'].mean(), inplace=True)\n",
    "# 用性别列的众数填充性别缺失值\n",
    "df['性别'].fillna(df['性别'].mode()[0], inplace=True)\n",
    "# 用成绩列的中位数填充成绩缺失值\n",
    "df['成绩'].fillna(df['成绩'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c9eec-76ef-4568-a1de-77f2a12ad274",
   "metadata": {},
   "source": [
    "【例4.3】演示对数据的归一化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d7e0e7-c9e8-47e2-b19d-a4bc09ba6e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler后的数据：\n",
      " [[-1.41421356 -1.41421356 -1.41421356]\n",
      " [-0.70710678 -0.70710678 -0.70710678]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.70710678  0.70710678  0.70710678]\n",
      " [ 1.41421356  1.41421356  1.41421356]]\n",
      "MinMaxScaler后的数据：\n",
      " [[0.   0.   0.  ]\n",
      " [0.25 0.25 0.25]\n",
      " [0.5  0.5  0.5 ]\n",
      " [0.75 0.75 0.75]\n",
      " [1.   1.   1.  ]]\n",
      "RobustScaler后的数据：\n",
      " [[-1.  -1.  -1. ]\n",
      " [-0.5 -0.5 -0.5]\n",
      " [ 0.   0.   0. ]\n",
      " [ 0.5  0.5  0.5]\n",
      " [ 1.   1.   1. ]]\n",
      "MaxAbsScaler后的数据：\n",
      " [[0.2 0.2 0.2]\n",
      " [0.4 0.4 0.4]\n",
      " [0.6 0.6 0.6]\n",
      " [0.8 0.8 0.8]\n",
      " [1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建示例数据\n",
    "data = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
    "                     'B': [10, 20, 30, 40, 50],\n",
    "                     'C': [100, 200, 300, 400, 500]})\n",
    "# StandardScaler 将数据进行标准化处理，使得数据的均值为0，方差为1。\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"StandardScaler后的数据：\\n\", scaled_data)\n",
    "# MinMaxScaler 将数据进行缩放处理，使得数据在指定的范围内。\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = minmax_scaler.fit_transform(data)\n",
    "print(\"MinMaxScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# RobustScaler 与StandardScaler类似，但是可以处理异常值。\n",
    "robust_scaler = RobustScaler()\n",
    "scaled_data = robust_scaler.fit_transform(data)\n",
    "print(\"RobustScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# MaxAbsScaler 将数据缩放到[-1,1]的范围内，适用于稀疏数据。\n",
    "maxabs_scaler = MaxAbsScaler()\n",
    "scaled_data = maxabs_scaler.fit_transform(data)\n",
    "print(\"MaxAbsScaler后的数据：\\n\", scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca3a342-fa7c-4a6d-8590-36014617fd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler后的数据：\n",
      " [[-1.41421356 -1.41421356 -1.41421356]\n",
      " [-0.70710678 -0.70710678 -0.70710678]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.70710678  0.70710678  0.70710678]\n",
      " [ 1.41421356  1.41421356  1.41421356]]\n",
      "MinMaxScaler后的数据：\n",
      " [[0.   0.   0.  ]\n",
      " [0.25 0.25 0.25]\n",
      " [0.5  0.5  0.5 ]\n",
      " [0.75 0.75 0.75]\n",
      " [1.   1.   1.  ]]\n",
      "RobustScaler后的数据：\n",
      " [[-1.  -1.  -1. ]\n",
      " [-0.5 -0.5 -0.5]\n",
      " [ 0.   0.   0. ]\n",
      " [ 0.5  0.5  0.5]\n",
      " [ 1.   1.   1. ]]\n",
      "MaxAbsScaler后的数据：\n",
      " [[0.2 0.2 0.2]\n",
      " [0.4 0.4 0.4]\n",
      " [0.6 0.6 0.6]\n",
      " [0.8 0.8 0.8]\n",
      " [1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建示例数据\n",
    "data = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
    "                     'B': [10, 20, 30, 40, 50],\n",
    "                     'C': [100, 200, 300, 400, 500]})\n",
    "# StandardScaler 将数据进行标准化处理，使得数据的均值为0，方差为1。\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"StandardScaler后的数据：\\n\", scaled_data)\n",
    "# MinMaxScaler 将数据进行缩放处理，使得数据在指定的范围内。\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = minmax_scaler.fit_transform(data)\n",
    "print(\"MinMaxScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# RobustScaler 与StandardScaler类似，但是可以处理异常值。\n",
    "robust_scaler = RobustScaler()\n",
    "scaled_data = robust_scaler.fit_transform(data)\n",
    "print(\"RobustScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# MaxAbsScaler 将数据缩放到[-1,1]的范围内，适用于稀疏数据。\n",
    "maxabs_scaler = MaxAbsScaler()\n",
    "scaled_data = maxabs_scaler.fit_transform(data)\n",
    "print(\"MaxAbsScaler后的数据：\\n\", scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2efc7-3c8f-4749-842d-156f4aa818e9",
   "metadata": {},
   "source": [
    "【例4.5】L1正则化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9438534-c6ba-4ee2-ae24-949025febb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.66666667e-01 3.33333333e-01 5.00000000e-01]\n",
      " [7.84313725e-01 9.80392157e-02 1.17647059e-01]\n",
      " [8.99820378e-05 9.99799534e-01 1.10484274e-04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2, 3], [4000, 500, 600], [79, 877777, 97]])\n",
    "\n",
    "transformer = Normalizer(norm='l1')\n",
    "X_normalized = transformer.transform(X)\n",
    "\n",
    "print(X_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d2156-2606-422b-ba31-8e84a6f4a954",
   "metadata": {},
   "source": [
    "【例4.6】L2正则化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f65e54-c541-4451-9d62-4143b60e7d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26726124 0.53452248 0.80178373]\n",
      " [0.45584231 0.56980288 0.68376346]\n",
      " [0.50257071 0.57436653 0.64616234]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "transformer = Normalizer(norm='l2')\n",
    "X_normalized = transformer.transform(X)\n",
    "\n",
    "print(X_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97aa0b-a623-4f2c-a2ad-331aea20b092",
   "metadata": {},
   "source": [
    "【例4.7】将['apple', 'banana', 'pear']进行LabelEncoder。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e35c9ae-fda5-4598-bc98-abd62220bc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 创建 LabelEncoder 对象\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 定义标签列表\n",
    "labels = ['apple', 'banana', 'pear']\n",
    "\n",
    "# 使用 LabelEncoder 对标签进行编码\n",
    "encoded_labels = le.fit_transform(labels)\n",
    "# 输出编码结果\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b8081-1518-4037-8022-2c65f65a7ba8",
   "metadata": {},
   "source": [
    "【例4.8】使用scikit-learn将[“红色”，“蓝色”，“绿色”]进行OneHotEncoder编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc971ef6-5978-475f-8a81-05355ee217af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "# 创建 OneHotEncoder 对象\n",
    "ohe = OneHotEncoder()\n",
    "# 定义标签列表\n",
    "labels = ['红色', '蓝色', '绿色']\n",
    "# 使用 OneHotEncoder 对标签进行独热编码\n",
    "encoded_labels = ohe.fit_transform(np.array(labels).reshape(-1, 1)).toarray()\n",
    "# 输出独热编码结果\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5dd4a-5440-49d7-b623-2e20cc5fa427",
   "metadata": {},
   "source": [
    "【例4.9】使用scikit-learn将文本分成单个单词（称为标记），并计算每个标记在文本中出现的频率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16735e2-82aa-46a6-8051-55e06b8beb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "# 创建 CountVectorizer 对象，并拟合文本数据\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# 转换文本数据\n",
    "vectorized_corpus = vectorizer.transform(corpus)\n",
    "# 将稀疏矩阵转换为密集矩阵并打印结果\n",
    "print(vectorized_corpus.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408d863-7eee-44e1-9e72-f18624facb88",
   "metadata": {},
   "source": [
    "【例4.10】使用TF-IDF对字符串进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c9444b-0da0-4347-b02f-94f3872d3735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t0.43306684852870914\n",
      "  (0, 7)\t0.43306684852870914\n",
      "  (0, 4)\t0.33631504064053513\n",
      "  (0, 3)\t0.5694308628404254\n",
      "  (0, 2)\t0.43306684852870914\n",
      "  (1, 8)\t0.3083318691673373\n",
      "  (1, 7)\t0.3083318691673373\n",
      "  (1, 5)\t0.8108387095324792\n",
      "  (1, 4)\t0.23944720188599447\n",
      "  (1, 2)\t0.3083318691673373\n",
      "  (2, 6)\t0.546454011634009\n",
      "  (2, 4)\t0.3227445421804912\n",
      "  (2, 1)\t0.546454011634009\n",
      "  (2, 0)\t0.546454011634009\n",
      "[[0.         0.         0.43306685 0.56943086 0.33631504 0.\n",
      "  0.         0.43306685 0.43306685]\n",
      " [0.         0.         0.30833187 0.         0.2394472  0.81083871\n",
      "  0.         0.30833187 0.30833187]\n",
      " [0.54645401 0.54645401 0.         0.         0.32274454 0.\n",
      "  0.54645401 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'That is also a book!!']\n",
    "#创建 TfidfVectorizer 对象，并拟合文本数据\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "#转换文本数据\n",
    "vectorized_corpus = vectorizer.transform(corpus)\n",
    "print(vectorized_corpus)\n",
    "#将稀疏矩阵转换为密集矩阵并打印结果\n",
    "print(vectorized_corpus.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208a032-c372-4e1d-a14c-421ffc56cf02",
   "metadata": {},
   "source": [
    "【例4.11】下面是一个简单的示例代码，演示如何使用VarianceThreshold方法对数据集进行特征选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb7d8051-9375-48bd-a8cc-11ea2b737501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集大小：(150, 4), 特征选择后的数据集大小：(150, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 方差选择法，删除方差低于阈值的特征\n",
    "selector = VarianceThreshold(threshold=0.2)\n",
    "X_new = selector.fit_transform(X)\n",
    "\n",
    "# 输出选择后的数据集大小\n",
    "print(f\"原始数据集大小：{X.shape}, 特征选择后的数据集大小：{X_new.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591307c-08d2-4b18-8d82-6b40686316a7",
   "metadata": {},
   "source": [
    "【例4.12】卡方检验对数据集属性选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b222969-a03c-4a5d-87ab-4b3eac56ce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 使用 SelectKBest 方法和卡方检验选择最重要的两个特征\n",
    "selector = SelectKBest(chi2, k=2)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(selector.get_support())\n",
    "# 打印选择的特征的值\n",
    "print(X_new[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5310ac-b5fb-4cb7-85ec-7238953ac134",
   "metadata": {},
   "source": [
    "【例4.13】相关系数对数据集属性选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd82822c-7cc7-4d37-849d-175fc7145579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False  True False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False  True False False]\n",
      "[[1.471e-01 1.846e+02 2.654e-01]\n",
      " [7.017e-02 1.588e+02 1.860e-01]\n",
      " [1.279e-01 1.525e+02 2.430e-01]\n",
      " [1.052e-01 9.887e+01 2.575e-01]\n",
      " [1.043e-01 1.522e+02 1.625e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# 加载乳腺癌数据集\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# 使用 SelectKBest 方法和相关系数选择与分类目标相关性最高的两个特征\n",
    "selector = SelectKBest(f_regression, k=3)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(selector.get_support())\n",
    "# 打印选择的特征的值\n",
    "print(X_new[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "220277d9-8241-4ec7-8279-b35ce559f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[ True False  True  True]\n",
      "[[5.1 1.4 0.2]\n",
      " [4.9 1.4 0.2]\n",
      " [4.7 1.3 0.2]\n",
      " [4.6 1.5 0.2]\n",
      " [5.  1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# 使用 SelectKBest 方法和相关系数选择与分类目标相关性最高的两个特征\n",
    "print(X[:5])\n",
    "selector = SelectKBest(f_regression, k=3)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(selector.get_support())\n",
    "# 打印选择的特征的值\n",
    "print(X_new[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b0b342-8f5e-4ef0-9417-f68e29bfedbd",
   "metadata": {},
   "source": [
    "【例4.14】Wrapper方法对数据集属性选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85098f38-643b-4ff8-864e-ae4ea13b6584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "3\n",
      "[ True False  True  True]\n",
      "['sepal length (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# 使用 SelectKBest 方法和相关系数选择与分类目标相关性最高的两个特征\n",
    "print(X[:5])\n",
    "\n",
    "# 定义线性回归模型\n",
    "model = LinearRegression()\n",
    "\n",
    "# 使用 RFECV 方法选择最佳特征子集\n",
    "selector = RFECV(model, step=1, cv=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征的数量\n",
    "print(selector.n_features_)\n",
    "# 打印选择的特征的编号\n",
    "print(selector.support_)\n",
    "# 打印选择的特征的名称\n",
    "# 打印选择的特征的名称\n",
    "selected_feature_names = [name for name, selected in zip(iris.feature_names, selector.support_) if selected]\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86bd87-758d-49fe-b1d9-ce9227725ec8",
   "metadata": {},
   "source": [
    "【例4.15】使用 Lasso Regression 进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "590415a4-bd99-4186-ba27-e69163d7cc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'B'\n",
      " 'LSTAT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# 加载波士顿房价数据集\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "# 定义 Lasso 回归模型\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# 使用 Lasso 方法选择最佳特征子集\n",
    "model.fit(X, y)\n",
    "selector = model.coef_ != 0\n",
    "\n",
    "# 打印选择的特征的数量\n",
    "print(sum(selector))\n",
    "# 打印选择的特征的名称\n",
    "print(boston.feature_names[selector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdd9c918-3ed0-454f-983f-d268913752a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'] 共有10\n",
      "从中选择: 7\n",
      "结果: ['sex', 'bmi', 'bp', 's1', 's3', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# 加载糖尿病数据集\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# 定义 Lasso 回归模型\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# 使用 Lasso 方法选择最佳特征子集\n",
    "model.fit(X, y)\n",
    "selector = model.coef_ != 0\n",
    "\n",
    "# 打印选择的特征的数量\n",
    "\n",
    "# 打印选择的特征的名称\n",
    "print(diabetes.feature_names,f'共有{len(diabetes.feature_names)}')\n",
    "print('从中选择:',sum(selector))\n",
    "selected_feature_names = [name for name, selected in zip(diabetes.feature_names, selector) if selected]\n",
    "print('结果:',selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70e07b82-6cdf-41e6-94b8-d4a0c60c02c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['bmi', 's5']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Load the diabetes dataset as an alternative to load_boston\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Define a decision tree regression model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Use the decision tree method to select the best feature subset\n",
    "model.fit(X, y)\n",
    "selector = model.feature_importances_ > 0.1\n",
    "\n",
    "# Print the number of selected features\n",
    "print(sum(selector))\n",
    "# Print the names of the selected features\n",
    "selected_feature_names = [name for name, selected in zip(diabetes.feature_names, selector) if selected]\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfdcec-74b6-47b9-84b3-a30a031d6bd9",
   "metadata": {},
   "source": [
    "【例4.17】使用 PCA进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0760b30-30a6-448d-b0eb-b21042e571c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "# 使用PCA进行特征选择\n",
    "pca = PCA(n_components=2)\n",
    "X_new = pca.fit_transform(X)\n",
    "\n",
    "# 打印新数据的形状\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cacc5-cdf6-4ac9-954d-66d562b1c4b1",
   "metadata": {},
   "source": [
    "【例4.17】使用Kernel PCA进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "152ebe3a-8ec9-4dd3-b9b2-0cfa4c254e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14175409]\n",
      " [ 0.18173951]\n",
      " [ 0.30018073]\n",
      " [ 0.33842195]\n",
      " [-0.60061192]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# 生成随机数据集\n",
    "X, y = make_circles(n_samples=1000, random_state=42, noise=0.1, factor=0.5)\n",
    "\n",
    "# 使用 Kernel PCA 方法进行特征选择\n",
    "kpca = KernelPCA(kernel='rbf', n_components=1)\n",
    "X_new = kpca.fit_transform(X)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(X_new[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32921e10-dd6c-4cb7-bd40-c9efe0b906d0",
   "metadata": {},
   "source": [
    "【例4.19】使用LDA进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "493a7da6-47bc-4586-a169-b54706bd67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 加载 iris 数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 定义 LDA 模型\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "# 使用 LDA 进行降维\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# 打印降维后的数据形状\n",
    "print(X.shape,X_lda.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fc991-22a2-4b0f-be0b-058cd9e71047",
   "metadata": {},
   "source": [
    "【例4.19】使用t-SNE进行特征选择的示例代码。\n",
    "下面是使用t-SNE进行特征选择的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "710e8998-834c-4309-b78c-735ae77acef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-12.477135 -18.492872]\n",
      " [-11.739949 -21.047226]\n",
      " [-10.8905   -20.405169]\n",
      " [-10.903398 -20.891945]\n",
      " [-12.171896 -18.25238 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 使用TSNE进行特征选择\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# 打印降维后的数据\n",
    "print(X_tsne[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348820d-adb5-4720-99f1-8d410f378ccd",
   "metadata": {},
   "source": [
    "【例4.20】Isomap计算案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a452aae3-3ec8-4dc6-8fd9-bc6efd46abdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "# 加载 digits 数据集\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# 定义 Isomap 模型\n",
    "isomap = Isomap(n_components=2, n_neighbors=10)\n",
    "\n",
    "# 使用 Isomap 进行降维\n",
    "X_isomap = isomap.fit_transform(X)\n",
    "\n",
    "# 打印降维后的数据形状\n",
    "print(X_isomap.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89da5d-455f-4141-91f4-6306127404b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
