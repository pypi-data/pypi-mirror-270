{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6630b7-f094-4f52-8bc8-c4a9ba706842",
   "metadata": {},
   "source": [
    "## 【例3.1】使用 OpenML 模块获取数据集。\n",
    "首先，在OpenML网站查找iris数据集的元数据信息（见图 3.9），得到数据ID为61，然后再代码中按照ID获取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35bae2e6-2a64-4cdc-9473-c8faebc8e200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25012\\2713158364.py:2: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  iris = openml.datasets.get_dataset(61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallength  sepalwidth  petallength  petalwidth           class\n",
       "0            5.1         3.5          1.4         0.2     Iris-setosa\n",
       "1            4.9         3.0          1.4         0.2     Iris-setosa\n",
       "2            4.7         3.2          1.3         0.2     Iris-setosa\n",
       "3            4.6         3.1          1.5         0.2     Iris-setosa\n",
       "4            5.0         3.6          1.4         0.2     Iris-setosa\n",
       "..           ...         ...          ...         ...             ...\n",
       "145          6.7         3.0          5.2         2.3  Iris-virginica\n",
       "146          6.3         2.5          5.0         1.9  Iris-virginica\n",
       "147          6.5         3.0          5.2         2.0  Iris-virginica\n",
       "148          6.2         3.4          5.4         2.3  Iris-virginica\n",
       "149          5.9         3.0          5.1         1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openml\n",
    "iris = openml.datasets.get_dataset(61)\n",
    "X, y, a, b = iris.get_data()\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa66d591-210b-4954-b4f7-83d6c26f72d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepallength  sepalwidth  petallength  petalwidth           class\n",
       "0            5.1         3.5          1.4         0.2     Iris-setosa\n",
       "1            4.9         3.0          1.4         0.2     Iris-setosa\n",
       "2            4.7         3.2          1.3         0.2     Iris-setosa\n",
       "3            4.6         3.1          1.5         0.2     Iris-setosa\n",
       "4            5.0         3.6          1.4         0.2     Iris-setosa\n",
       "..           ...         ...          ...         ...             ...\n",
       "145          6.7         3.0          5.2         2.3  Iris-virginica\n",
       "146          6.3         2.5          5.0         1.9  Iris-virginica\n",
       "147          6.5         3.0          5.2         2.0  Iris-virginica\n",
       "148          6.2         3.4          5.4         2.3  Iris-virginica\n",
       "149          5.9         3.0          5.1         1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openml\n",
    "\n",
    "# Explicitly set download parameters to suppress the FutureWarning\n",
    "iris = openml.datasets.get_dataset(61, download_data=True, download_qualities=True, download_features_meta_data=True)\n",
    "\n",
    "# Retrieve features (X) and labels (y)\n",
    "X, y, a, b = iris.get_data()\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489c7f89-3cb3-4ef0-877d-6e58eaaf3473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893b06d9-0629-4aa1-8f23-e08f5e480f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8371854-d51d-4337-abad-bfe22cbb640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'class']\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece9cde6-d151-4d04-8efa-d58440bc746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):\n",
      "     sepallength  sepalwidth  petallength  petalwidth           class\n",
      "0            5.1         3.5          1.4         0.2     Iris-setosa\n",
      "1            4.9         3.0          1.4         0.2     Iris-setosa\n",
      "2            4.7         3.2          1.3         0.2     Iris-setosa\n",
      "3            4.6         3.1          1.5         0.2     Iris-setosa\n",
      "4            5.0         3.6          1.4         0.2     Iris-setosa\n",
      "..           ...         ...          ...         ...             ...\n",
      "145          6.7         3.0          5.2         2.3  Iris-virginica\n",
      "146          6.3         2.5          5.0         1.9  Iris-virginica\n",
      "147          6.5         3.0          5.2         2.0  Iris-virginica\n",
      "148          6.2         3.4          5.4         2.3  Iris-virginica\n",
      "149          5.9         3.0          5.1         1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "\n",
      "Labels (y):\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25012\\766160889.py:4: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  iris = openml.datasets.get_dataset(61)\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "\n",
    "# Get the Iris dataset (ID 61)\n",
    "iris = openml.datasets.get_dataset(61)\n",
    "\n",
    "# Retrieve features (X) and labels (y)\n",
    "data_tuple = iris.get_data()\n",
    "X, y, _, _ = data_tuple\n",
    "\n",
    "# Print features and labels\n",
    "print(\"Features (X):\")\n",
    "print(X)\n",
    "print(\"\\nLabels (y):\")\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1041263-bcff-44a1-bc2d-df55575f8836",
   "metadata": {},
   "source": [
    "## 【例3.2】演示Scikit-learn获取OpenML数据集。数据集的名称可以在OpenML网站上查询获得，这里数据集的名称为iris，。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4c8b8b-55b9-4b06-a26e-d7b885f60e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n",
      "**Author**: R.A. Fisher  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Iris) - 1936 - Donated by Michael Marshall  \n",
      "**Please cite**:   \n",
      "\n",
      "**Iris Plants Database**  \n",
      "This is perhaps the best known database to be found in the pattern recognition literature.  Fisher's paper is a classic in the field and is referenced frequently to this day.  (See Duda & Hart, for example.)  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is     linearly separable from the other 2; the latter are NOT linearly separable from each other.\n",
      "\n",
      "Predicted attribute: class of iris plant.  \n",
      "This is an exceedingly simple domain.  \n",
      " \n",
      "### Attribute Information:\n",
      "    1. sepal length in cm\n",
      "    2. sepal width in cm\n",
      "    3. petal length in cm\n",
      "    4. petal width in cm\n",
      "    5. class: \n",
      "       -- Iris Setosa\n",
      "       -- Iris Versicolour\n",
      "       -- Iris Virginica\n",
      "\n",
      "Downloaded from openml.org.\n",
      "(150, 4) (150,)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "# 获取openml数据集\n",
    "dataset=fetch_openml(name='iris', version=1, data_home='./data', return_X_y=False, as_frame=True)#,parser='auto')\n",
    "print(type(dataset))\n",
    "# 输出数据集的描述信息\n",
    "print(dataset.DESCR)\n",
    "# 输出特征数据和标签数据\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "print(X.shape, y.shape)\n",
    "print(type(X),type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0a85c-0b7c-437c-925c-959db2397197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "# 获取Iris数据集\n",
    "iris = openml.datasets.get_dataset(61)\n",
    "print(iris.features)\n",
    "\n",
    "# 获取数据集的元数据信息\n",
    "dataset_info = iris.get_data()\n",
    "print(\"\\n数据集介绍:\")\n",
    "print(f\"{iris.name} 数据集包含 {iris.qualities['NumberOfInstances']} 个样本，每个样本有 {iris.qualities['NumberOfFeatures']} 个特征。\")\n",
    "print(f\"该数据集用于 {iris.format} 任务，目标是 {iris.default_target_attribute}。\")\n",
    "print(f\"描述: {iris.description}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea8d12-9b4f-4755-8e0a-24cecc44ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "info=iris.get_data() #返回一个包含四个元素的元组 (X, y, attribute_names, _)\n",
    "\n",
    "for i in info:\n",
    "    print(f'类型：{type(i)}\\n{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28e84b-297e-4dfc-bf24-1fba8839e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "，其中：\n",
    "\n",
    "X: 特征数据，通常是一个二维数组或 Pandas DataFrame。\n",
    "y: 标签数据，通常是一个一维数组或 Pandas Series。\n",
    "attribute_names: 特征的名称列表。\n",
    "_: 其他信息，这里通常为空。\n",
    "你可以根据需要使用其中的信息，比如 X 和 y 是构成数据集的特征和标签数据，attribute_names 是特征的名称列表。在你的示例中，你只需关注 X 和 y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3759b8-c8dd-4935-bdf3-7aead4406c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e02e92-8778-4cfe-b935-7aec70ef7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载Scikit-learn内置的数据集，这里以鸢尾花数据集为例\n",
    "data = load_iris()\n",
    "\n",
    "# 输出数据集的元数据信息\n",
    "print(\"数据集名称:\", data['DESCR'])\n",
    "print(\"特征数:\", data['data'].shape[1])\n",
    "print(\"样本数:\", data['data'].shape[0])\n",
    "print(\"类别:\", set(data['target']))\n",
    "# 可以输出其他元数据信息\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf09eee-6a83-4f5b-bc38-e2073433139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.4】使用scikit-learn模块load_wine函数加酒数据集的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9ecd3-1013-4dc3-9e3f-b37942ffbcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec9810-9bf5-4ba3-bd45-4e0ea9ca20c4",
   "metadata": {},
   "source": [
    "## 【例3.3】演示Scikit-learn获取OpenML数据集iris、wine、mnist。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d50d81-016b-4aae-9ba5-002be0f56b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 使用 Parallel 和 delayed 函数并行下载数据集\n",
    "datasets = ['iris', 'wine', 'mnist_784']\n",
    "results = Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(fetch_openml)(name=d, version=1,cache=True,parser='auto') for d in datasets)\n",
    "\n",
    "# 打印下载完成的数据集的名称\n",
    "for r in results:\n",
    "    print(r['details']['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352189de-5866-46aa-b7d0-f8aacbccf19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# 使用 Parallel 和 delayed 函数并行下载数据集\n",
    "datasets = ['iris', 'wine', 'mnist_784']\n",
    "results = Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(fetch_openml)(name=d, version=1, cache=True, parser='auto') for d in datasets)\n",
    "\n",
    "# 打印下载完成的数据集的名称和信息\n",
    "for r in results:\n",
    "    print(f\"Dataset Name: {r['details']['name']}\")\n",
    "    print(f\"Dataset Info: {r['details']['info']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6608de6-6f98-4353-917b-81454b0b6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edbab2-295c-44de-80a1-afcff7e30d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "\n",
    "# Print the dataset description\n",
    "print(california_housing.DESCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e9584-a5c2-491d-9598-db9f6f316d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "print(wine.DESCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f3b88-e763-41ed-bc62-ddc0729902f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6af85476-9d73-41ac-b4b6-95c6f15ea1f3",
   "metadata": {},
   "source": [
    "## 【例3.5】使用make_blobs、make_classification、make_regression函数生成数据集的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d27ca4-1116-4752-b78a-62e98eba208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_classification, make_regression\n",
    "# 使用 make_blobs 生成 2 类聚类数据集\n",
    "X, y = make_blobs(n_samples=100, centers=2, random_state=42)\n",
    "# 使用 make_classification 生成 3 类多分类数据集\n",
    "X, y = make_classification(n_samples=100, n_classes=3, random_state=42)\n",
    "# 使用 make_regression 生成回归数据集\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51adb0-01eb-4e28-89c1-67d7454cf321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_classification, make_regression\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Example 3.5: Generating datasets using make_blobs, make_classification, and make_regression\n",
    "\n",
    "# 1. make_blobs: Create a blob of points with specified centers and standard deviation\n",
    "X_blob, y_blob = make_blobs(n_samples=300, centers=3, random_state=42, cluster_std=1.0)\n",
    "plt.scatter(X_blob[:, 0], X_blob[:, 1], c=y_blob, cmap='viridis')\n",
    "plt.title(\"make_blobs Example\")\n",
    "# Save the figure as a high-resolution image\n",
    "plt.savefig(\"make_blobs_example.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 2. make_classification: Create a random classification dataset with specified parameters\n",
    "X_class, y_class = make_classification(n_samples=300, n_features=2, n_informative=2,\n",
    "                                       n_redundant=0, n_clusters_per_class=1, random_state=42)\n",
    "plt.scatter(X_class[:, 0], X_class[:, 1], c=y_class, cmap='viridis')\n",
    "plt.title(\"make_classification Example\")\n",
    "# Save the figure as a high-resolution image\n",
    "plt.savefig(\"make_classification_example.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 3. make_regression: Create a random regression dataset with specified parameters\n",
    "X_reg, y_reg = make_regression(n_samples=300, n_features=1, noise=20, random_state=42)\n",
    "plt.scatter(X_reg, y_reg, color='blue')\n",
    "plt.title(\"make_regression Example\")\n",
    "# Save the figure as a high-resolution image\n",
    "plt.savefig(\"make_regression_example.png\", dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5875d479-8261-4eb3-a22c-38c31ea74cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3403d6-8285-44cb-a5d9-3a17077ecc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.6】使用scikit-learn 划分iris数据集的训练集、验证集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc960f1-f17f-491d-8b1b-664a3c075355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 加载 iris 数据集\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 再从训练集中划分为训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 打印划分结果的形状\n",
    "print(\"训练集形状:\", X_train.shape, y_train.shape)\n",
    "print(\"验证集形状:\", X_val.shape, y_val.shape)\n",
    "print(\"测试集形状:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8bb17-64f9-41a3-be8e-be2e7101a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载 iris 数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 设置 Bootstrap 抽样的次数\n",
    "n_iterations = 5  # 你可以根据需要设置不同的次数\n",
    "\n",
    "# 执行 Bootstrap 数据划分\n",
    "for iteration in range(n_iterations):\n",
    "    # 使用 resample 函数进行 Bootstrap 抽样\n",
    "    X_bootstrap, y_bootstrap = resample(X, y, random_state=iteration)\n",
    "    \n",
    "    # 在这里，你可以使用 X_bootstrap 和 y_bootstrap 进行模型训练和评估\n",
    "    # 例如，可以使用 X_bootstrap 和 y_bootstrap 训练一个模型，然后在测试集上进行评估\n",
    "    # 这里仅作为演示，你可以根据具体任务进行模型的训练和评估\n",
    "    print(f\"Iteration {iteration + 1}: Sampled {len(X_bootstrap)} data points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319acb4a-dfe6-4d79-befb-78804007dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.6】数据的统计特征获取。可以使用Pandas中DataFrame对象的相关函数实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af61f79-7375-4a54-8a84-4843e835b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建一个包含数据的DataFrame\n",
    "data = {'Value': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# (1) 最小值\n",
    "min_value = df['Value'].min()\n",
    "\n",
    "# (2) 最大值\n",
    "max_value = df['Value'].max()\n",
    "\n",
    "# (3) 平均数\n",
    "mean_value = df['Value'].mean()\n",
    "\n",
    "# (4) 中位数\n",
    "median_value = df['Value'].median()\n",
    "\n",
    "# (5) 众数\n",
    "mode_value = df['Value'].mode()[0]  # 众数可能有多个，取第一个\n",
    "\n",
    "# (6) 方差\n",
    "variance_value = df['Value'].var()\n",
    "\n",
    "# (7) 标准差\n",
    "std_deviation_value = df['Value'].std()\n",
    "\n",
    "# (8) 百分位数\n",
    "percentile_value = df['Value'].quantile(0.75)  # 例如，获取第75个百分位数\n",
    "\n",
    "# (9) 偏度\n",
    "skewness_value = df['Value'].skew()\n",
    "\n",
    "# (10) 峰度\n",
    "kurtosis_value = df['Value'].kurt()\n",
    "\n",
    "# 打印结果\n",
    "print(f\"最小值: {min_value}\")\n",
    "print(f\"最大值: {max_value}\")\n",
    "print(f\"平均数: {mean_value}\")\n",
    "print(f\"中位数: {median_value}\")\n",
    "print(f\"众数: {mode_value}\")\n",
    "print(f\"方差: {variance_value}\")\n",
    "print(f\"标准差: {std_deviation_value}\")\n",
    "print(f\"百分位数(75%): {percentile_value}\")\n",
    "print(f\"偏度: {skewness_value}\")\n",
    "print(f\"峰度: {kurtosis_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9eb95-eaef-4a1a-9872-803bb44ca8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f03a4e-1560-4d13-8b97-7850ec1b3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.7】切比雪夫距离计算示例。\n",
    "使用NumPy库可以很方便地计算切比雪夫距离，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2370ac-38ab-4ec1-ad34-a2e7750b1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 两个n维向量\n",
    "A = np.array([1, 2, 3])\n",
    "B = np.array([4, 7, 15])\n",
    "# 计算切比雪夫距离\n",
    "d = np.abs(A - B).max()\n",
    "print(\"切比雪夫距离：\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc52ed1-ca9c-4cf1-96a9-40551e439dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "# 多组n维向量\n",
    "X = np.array([[3, 2, 1], [11, 22,33]])\n",
    "# 计算多组向量之间的切比雪夫距离\n",
    "d = pairwise_distances(X, metric='chebyshev')\n",
    "print(\"切比雪夫距离矩阵：\\n\", d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d72ed-2f02-48da-a8fb-f37c30cac486",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pairwise_distances(X, metric='chebyshev')\n",
    "d = pairwise_distances(X, metric='euclidean')\n",
    "d = pairwise_distances(X, metric='minkowski', p=2)\n",
    "d = pairwise_distances(X, metric='manhattan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c42b7-356b-402d-b398-2e19e27eda2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "# 示例数据\n",
    "X = np.array([[1, 2, 3], [7, 8, 9]])\n",
    "dis=['euclidean','manhattan','chebyshev','minkowski','cosine','jaccard','correlation']\n",
    "for d in dis:\n",
    "    dd=pairwise_distances(X, metric=d)\n",
    "    print(f'{d=}\\n',dd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8052fe-8d12-4c95-9e12-890f7ccb03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "欧氏距离 ('euclidean'):\n",
    "\n",
    "计算两点之间的直线距离。\n",
    "曼哈顿距离 ('manhattan'):\n",
    "\n",
    "计算两点之间在坐标轴上的绝对距离之和。\n",
    "切比雪夫距离 ('chebyshev'):\n",
    "\n",
    "计算两点之间在所有坐标轴上的最大绝对差值。\n",
    "明可夫斯基距离 ('minkowski'):\n",
    "\n",
    "通过设置参数 p 来指定，当 p=2 时即为欧氏距离。\n",
    "汉明距离 ('hamming'):\n",
    "\n",
    "用于二进制数据的距离度量，计算两个相同长度的二进制向量之间的不同位数。\n",
    "余弦相似度 ('cosine'):\n",
    "\n",
    "计算两个向量之间的余弦值，用于测量它们的夹角的余弦。\n",
    "Jaccard 距离 ('jaccard'):\n",
    "\n",
    "用于计算两个集合之间的 Jaccard 距离，即交集与并集的比率的补集。\n",
    "汉明贝塔距离 ('hamming_beta'):\n",
    "\n",
    "汉明贝塔距离是汉明距离的一种变体。\n",
    "布雷柯莱距离 ('braycurtis'):\n",
    "\n",
    "计算两个向量之间的布雷柯莱距离，用于测量它们的绝对差值的比率。\n",
    "皮尔逊相关系数 ('correlation'):\n",
    "\n",
    "计算两个向量之间的皮尔逊相关系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966018c5-b49d-4412-a209-d2e5a3560906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "dis=['euclidean','manhattan','chebyshev','minkowski','cosine','jaccard','correlation']\n",
    "\n",
    "for d in dis:\n",
    "    dd=pairwise_distances(X, metric=d)\n",
    "    print(d)\n",
    "    print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc1ddc-c897-417d-9b80-3ff091bb15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# 计算两个变量之间的皮尔逊相关系数和p值\n",
    "x=[1, 2, 3]\n",
    "y=[4, 5, 6]\n",
    "corr, p_value = pearsonr(x, y)\n",
    "print('Pearson correlation coefficient:', corr)\n",
    "print('p-value:', p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4e818-0010-45d4-b2f5-bc1b0ef23315",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.8】曼哈顿距离计算示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d3a23-e47f-4466-ab8e-df15cecd20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算欧氏距离矩阵\n",
    "euclidean_distance_matrix = pairwise_distances(X, metric='euclidean')\n",
    "\n",
    "# 计算闵可夫斯基距离矩阵（p=2 对应欧氏距离）\n",
    "minkowski_distance_matrix = pairwise_distances(X, metric='minkowski', p=2)\n",
    "\n",
    "print(\"欧氏距离矩阵:\")\n",
    "print(euclidean_distance_matrix)\n",
    "\n",
    "print(\"\\n闵可夫斯基距离矩阵:\")\n",
    "print(minkowski_distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc4825-20d7-4d85-a252-4e4ebf968920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据矩阵\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算曼哈顿距离矩阵\n",
    "manhattan_distance_matrix = pairwise_distances(X, metric='manhattan')\n",
    "\n",
    "print(\"曼哈顿距离矩阵:\")\n",
    "print(manhattan_distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b7cf4-fff7-4cf6-b1d4-010e784e691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# 示例数据矩阵\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# 计算欧氏距离矩阵\n",
    "euclidean_distance_matrix = pairwise_distances(X, metric='euclidean')\n",
    "\n",
    "print(\"欧氏距离矩阵:\")\n",
    "print(euclidean_distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2be731-2436-4f18-9939-2fe32386ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 二维空间中两个点的曼哈顿距离\n",
    "point1 = np.array([1, 2])\n",
    "point2 = np.array([4, 6])\n",
    "manhattan_distance = np.sum(np.abs(point1 - point2))\n",
    "print(manhattan_distance) # 输出 7\n",
    "\n",
    "# 三维空间中两个点的曼哈顿距离\n",
    "point1 = np.array([1, 2, 3])\n",
    "point2 = np.array([4, 6, 8])\n",
    "manhattan_distance = np.sum(np.abs(point1 - point2))\n",
    "print(manhattan_distance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958f767-4f55-4950-8784-ad1919d5f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "# 二维空间中两个点的曼哈顿距离\n",
    "point1 = np.array([1, 2])\n",
    "point2 = np.array([4, 6])\n",
    "manhattan_distance = manhattan_distances([point1], [point2])[0][0]\n",
    "print(manhattan_distance) # 输出 7\n",
    "\n",
    "# 三维空间中两个点的曼哈顿距离\n",
    "point1 = np.array([1, 2, 3])\n",
    "point2 = np.array([4, 6, 8])\n",
    "manhattan_distance = manhattan_distances([point1], [point2])[0][0]\n",
    "print(manhattan_distance) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52718a-0543-4f72-b2ef-593618a666bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01437b-2a10-414e-a7f2-5e6042a03933",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.9】欧几里得距离计算示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d337782-48b5-463e-a6eb-004d72dbfe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x00 = np.array([1, 2, 3])\n",
    "x01 = np.array([4, 5, 6])\n",
    "x10 = np.array([7, 8, 9])\n",
    "x11 = np.array([10, 11, 12])\n",
    "distance00 = np.linalg.norm(x00 - x10)\n",
    "distance01 = np.linalg.norm(x00 - x11)\n",
    "distance10 = np.linalg.norm(x01 - x10)\n",
    "distance11 = np.linalg.norm(x01 - x11)\n",
    "print(distance00,distance01,distance10,distance11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d780813-f295-4390-b9c4-b8ee4f19f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "X = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "Y = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "distances = euclidean_distances(X, Y)\n",
    "print(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82907fd-eee9-453d-9daf-e4e175c52cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac896b-ca24-468a-af78-dc5e252e30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.10】闵可夫斯基距离计算示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41c1e7-37ad-4e6a-af8c-1ca6a010287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 二维空间中两个点的闵可夫斯基距离（p=1）\n",
    "point1 = np.array([1, 2])\n",
    "point2 = np.array([4, 6])\n",
    "minkowski_distance = np.power(np.sum(np.power(np.abs(point1 - point2), 1)), 1/1)\n",
    "print(minkowski_distance) # 输出 7\n",
    "# 三维空间中两个点的闵可夫斯基距离（p=2）\n",
    "point1 = np.array([1, 2, 3])\n",
    "point2 = np.array([4, 6, 8])\n",
    "minkowski_distance = np.power(np.sum(np.power(np.abs(point1 - point2), 2)), 1/2)\n",
    "print(minkowski_distance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31feb527-0dc5-44c5-9ebc-08d74de8f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "# 计算二维空间中两个点的闵可夫斯基距离\n",
    "point1 = np.array([1, 2])\n",
    "point2 = np.array([4, 6])\n",
    "minkowski_distance = minkowski(point1, point2, p=3)\n",
    "print(minkowski_distance)  # 输出 4.49794144528\n",
    "\n",
    "# 计算三维空间中两个点的闵可夫斯基距离\n",
    "point1 = np.array([1, 2, 3])\n",
    "point2 = np.array([4, 6, 8])\n",
    "minkowski_distance = minkowski(point1, point2, p=4)\n",
    "print(minkowski_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67e805-2c6d-42e7-a924-542064742f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ccaa3-ce51-4c43-ac42-708174a941bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.11】余弦相似度计算示例。\n",
    "在numpy中，可以使用 numpy.dot() 函数和 numpy.linalg.norm() 函数计算两个向量的点积和向量范数，从而计算它们之间的余弦相似度。示例如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b9924-f229-4e08-86d2-048ab6875404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 计算两个向量的余弦相似度\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([4, 5, 6])\n",
    "cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "print(cosine_similarity) # 输出 0.974631846198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c8a99-126a-49ed-8f0d-a04a3c856d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "在scikit-learn中，可以使用 sklearn.metrics.pairwise.cosine_similarity() 函数计算两个向量之间的余弦相似度。示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d72878-a1a7-42aa-a083-2ac25e70b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 计算两个向量的余弦相似度\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([4, 5, 6])\n",
    "cosine_similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
    "print(cosine_similarity) # 输出 0.974631846198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2964bb-a9e7-426f-9d89-ee16afbf9096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c924b9e-d34b-4bb1-826f-41c3ae4093f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.12】Jaccard相似系数计算示例。\n",
    "在Numpy中，可以使用 intersect1d 和 union1d 函数来计算两个集合的交集和并集。使用方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8ef60-52dd-47c9-adb6-b666856489ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 计算两个集合的交集和并集\n",
    "intersection = np.intersect1d(A, B)\n",
    "union = np.union1d(A, B)\n",
    "# 计算Jaccard相似系数\n",
    "jaccard_similarity = intersection.size / union.size\n",
    "print('Jaccard similarity coefficient:', jaccard_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52990e6-e9a1-4c19-a080-f6f3b7a94c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "其中，A 和 B 分别是要计算相似度的两个集合，intersection 和 union 分别是它们的交集和并集，jaccard_similarity 是它们的Jaccard相似系数。\n",
    "在scikit-learn中，可以使用 jaccard_score 函数来计算两个集合的Jaccard相似系数。使用方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc23e7-b628-4e74-acca-460099d6ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "# Example multiclass targets\n",
    "y_true = np.array([0, 1, 2, 2, 3])\n",
    "y_pred = np.array([0, 2, 2, 2, 3])\n",
    "\n",
    "# Calculate Jaccard similarity coefficient\n",
    "jaccard_similarity = jaccard_score(y_true, y_pred, average='micro')\n",
    "print('Jaccard similarity coefficient:', jaccard_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a21bf-53ca-42ff-843c-c734af13f463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6f199-872a-4492-bbc2-3ece3edfda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.13】VDM计算示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d368d-592b-4c59-b676-c135cbd86f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_vdm(feature, target):\n",
    "    unique_values = np.unique(feature)  # 获取特征的唯一取值\n",
    "    vdm_scores = {}  # 用于存储每个取值的VDM得分\n",
    "\n",
    "    for value in unique_values:\n",
    "        indices = np.where(feature == value)[0]  # 获取特征取值等于value的样本索引\n",
    "        class_counts = np.bincount(target[indices])  # 统计对应样本索引的目标类别计数\n",
    "\n",
    "        total_instances = len(indices)  # 特征取值等于value的样本总数\n",
    "        class_probabilities = class_counts / total_instances  # 目标类别的概率分布\n",
    "\n",
    "        vdm_score = np.sum(np.abs(class_probabilities - 1/len(np.unique(target))))  # 计算VDM得分\n",
    "        vdm_scores[value] = vdm_score\n",
    "\n",
    "    return vdm_scores\n",
    "\n",
    "# 示例数据\n",
    "feature = np.array(['A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'])\n",
    "target = np.array([0, 0, 1, 1, 1, 0, 0, 1, 1])\n",
    "\n",
    "vdm_scores = calculate_vdm(feature, target)\n",
    "print(\"VDM scores:\")\n",
    "for value, score in vdm_scores.items():\n",
    "    print(f\"{value}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84078a2d-7fca-4481-a1af-cfe8d18ae391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# 示例二进制数据矩阵（适用于 Jaccard 相似系数）\n",
    "binary_X = np.array([[0, 1, 0], [1, 0, 1], [1, 1, 0]])\n",
    "\n",
    "# 计算 Jaccard 相似系数矩阵\n",
    "jaccard_similarity_matrix = pairwise_distances(binary_X, metric='jaccard')\n",
    "\n",
    "print(\"Jaccard 相似系数矩阵:\")\n",
    "print(jaccard_similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cef22-43a2-4ded-9db6-82498d562fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame([[0, 1, 0], [1, 0, 1], [1, 1, 0]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbca331-6049-44d5-a6b3-9552b82440fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd86ac-b8ca-480e-97b4-202cf96af92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例二进制数据矩阵（适用于 Jaccard 相似系数）\n",
    "binary_X = np.array([[0, 1, 0], [1, 0, 1], [1, 1, 0]])\n",
    "\n",
    "# 计算 Jaccard 相似系数矩阵\n",
    "jaccard_similarity_matrix = pairwise_distances(df.values, metric='jaccard')\n",
    "\n",
    "print(\"Jaccard 相似系数矩阵:\")\n",
    "print(jaccard_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4b2be-e61a-47fb-a8e9-61b27c1f78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame([[0, 1, 0], [1, 0, 1], [1, 1, 0]])\n",
    "\n",
    "# 将 DataFrame 转换为 NumPy 数组\n",
    "data_array = df.to_numpy()\n",
    "\n",
    "# 计算 Jaccard 相似系数矩阵\n",
    "jaccard_similarity_matrix = pairwise_distances(data_array, metric='jaccard')\n",
    "\n",
    "# 打印 Jaccard 相似系数矩阵\n",
    "print(\"Jaccard 相似系数矩阵:\")\n",
    "print(jaccard_similarity_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9871fe-84f8-4583-b2a2-80c40bab14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5499af1-7e8f-420f-9fdb-ede82ec268f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ab09d-4f30-480d-ab42-dc527090c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.14】皮尔逊相关系数计算案例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e16ac-e809-4679-a62d-188ada9f87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# 计算两个变量之间的皮尔逊相关系数和p值\n",
    "corr, p_value = pearsonr(x, y)\n",
    "print('Pearson correlation coefficient:', corr)\n",
    "print('p-value:', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cca649-ed10-4c9d-852c-7f15082e7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 5, 8, 10])\n",
    "\n",
    "# 使用 NumPy 计算皮尔逊相关系数\n",
    "r_np = np.corrcoef(x, y)[0, 1]\n",
    "print('NumPy 计算的皮尔逊相关系数：', r_np)\n",
    "\n",
    "# 使用 SciPy 计算皮尔逊相关系数\n",
    "r_sp, p_value = pearsonr(x, y)\n",
    "print('SciPy 计算的皮尔逊相关系数：', r_sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc021a-7c52-4e33-9108-ba98467a4946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c8307-e510-4693-9d1a-f1e89f717340",
   "metadata": {},
   "outputs": [],
   "source": [
    "【例3.15】斯皮尔曼相关系数计算案例。\n",
    "使用NumPy和SciPy库可以计算斯皮尔曼相关系数，代码示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033453c-0a0d-4085-9999-d298177d6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# 创建两个随机变量\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([5, 4, 3, 2, 1])\n",
    "\n",
    "# 计算斯皮尔曼相关系数和p值\n",
    "corr, p_value = spearmanr(x, y)\n",
    "\n",
    "print(\"Spearman correlation coefficient:\", corr)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff4d1e-6a66-42f7-8361-4eb0941e642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "在 scikit-learn 中，可以使用 spearmanr 函数计算两个变量之间的斯皮尔曼相关系数。示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c487367-eecd-41cc-a079-374946a7015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "# 定义两个变量\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 6, 8, 10]\n",
    "# 计算斯皮尔曼相关系数和 p 值\n",
    "corr, p_value = spearmanr(x, y)\n",
    "print(\"斯皮尔曼相关系数：\", corr)\n",
    "print(\"p 值：\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34b962-128a-4038-91fa-cfe49b80eca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
