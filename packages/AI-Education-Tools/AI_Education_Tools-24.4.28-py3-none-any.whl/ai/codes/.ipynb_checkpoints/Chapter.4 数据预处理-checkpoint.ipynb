{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0050e-b777-446a-9cf3-64ccebed8a67",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1317a4e7-0c4f-448d-ad98-b88887a069a8",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "source": [
    "## 【例4.1】发现缺失数据的常用方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1952f6f-1671-4830-b2fd-c997fff081b4",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "       'A': [1, 2, None, 4],\n",
    "       'B': [5, None, 7, 8],\n",
    "       'C': [9, 10, 11, 12]\n",
    "   })\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f1408-80fe-48b9-8ee5-576ee61e8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564f65a-430b-475a-adfb-8c81f505c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    " df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63904041-03f1-48bf-918a-fea4b02d9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bef755-0160-4530-ad81-86a010c37c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpolated = df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ee969-ca07-4866-9c7f-931a37333ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaaf718-5ad9-4b5a-b879-1c3df0b41d8c",
   "metadata": {},
   "source": [
    "【例4.2】以下是使用 pandas 和 scikit-learn 库进行数据清洗，包括处理缺失值、重复值和无效值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15039b-b1db-4c7d-8f11-7f0b9518d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 创建示例数据\n",
    "data = {'姓名': ['张三', '李四', '王五', '赵六', '小明'],\n",
    "        '年龄': [23, 26, None, 24, 25],\n",
    "        '性别': ['男', '男', '女', '男', None],\n",
    "        '成绩': [90, 80, 85, 92, None]}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119e847-9cb5-4723-b9a0-05ec0e6c8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb8655-8f5b-411d-a946-c8fe273935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()\n",
    "df['年龄'].fillna(df['年龄'].mean(), inplace=True)\n",
    "# 用性别列的众数填充性别缺失值\n",
    "df['性别'].fillna(df['性别'].mode()[0], inplace=True)\n",
    "# 用成绩列的中位数填充成绩缺失值\n",
    "df['成绩'].fillna(df['成绩'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c9eec-76ef-4568-a1de-77f2a12ad274",
   "metadata": {},
   "source": [
    "【例4.3】演示对数据的归一化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7e0e7-c9e8-47e2-b19d-a4bc09ba6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建示例数据\n",
    "data = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
    "                     'B': [10, 20, 30, 40, 50],\n",
    "                     'C': [100, 200, 300, 400, 500]})\n",
    "# StandardScaler 将数据进行标准化处理，使得数据的均值为0，方差为1。\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"StandardScaler后的数据：\\n\", scaled_data)\n",
    "# MinMaxScaler 将数据进行缩放处理，使得数据在指定的范围内。\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = minmax_scaler.fit_transform(data)\n",
    "print(\"MinMaxScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# RobustScaler 与StandardScaler类似，但是可以处理异常值。\n",
    "robust_scaler = RobustScaler()\n",
    "scaled_data = robust_scaler.fit_transform(data)\n",
    "print(\"RobustScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# MaxAbsScaler 将数据缩放到[-1,1]的范围内，适用于稀疏数据。\n",
    "maxabs_scaler = MaxAbsScaler()\n",
    "scaled_data = maxabs_scaler.fit_transform(data)\n",
    "print(\"MaxAbsScaler后的数据：\\n\", scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3a342-fa7c-4a6d-8590-36014617fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 创建示例数据\n",
    "data = pd.DataFrame({'A': [1, 2, 3, 4, 5],\n",
    "                     'B': [10, 20, 30, 40, 50],\n",
    "                     'C': [100, 200, 300, 400, 500]})\n",
    "# StandardScaler 将数据进行标准化处理，使得数据的均值为0，方差为1。\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(\"StandardScaler后的数据：\\n\", scaled_data)\n",
    "# MinMaxScaler 将数据进行缩放处理，使得数据在指定的范围内。\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = minmax_scaler.fit_transform(data)\n",
    "print(\"MinMaxScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# RobustScaler 与StandardScaler类似，但是可以处理异常值。\n",
    "robust_scaler = RobustScaler()\n",
    "scaled_data = robust_scaler.fit_transform(data)\n",
    "print(\"RobustScaler后的数据：\\n\", scaled_data)\n",
    "\n",
    "# MaxAbsScaler 将数据缩放到[-1,1]的范围内，适用于稀疏数据。\n",
    "maxabs_scaler = MaxAbsScaler()\n",
    "scaled_data = maxabs_scaler.fit_transform(data)\n",
    "print(\"MaxAbsScaler后的数据：\\n\", scaled_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2efc7-3c8f-4749-842d-156f4aa818e9",
   "metadata": {},
   "source": [
    "【例4.5】L1正则化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9438534-c6ba-4ee2-ae24-949025febb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2, 3], [4000, 500, 600], [79, 877777, 97]])\n",
    "\n",
    "transformer = Normalizer(norm='l1')\n",
    "X_normalized = transformer.transform(X)\n",
    "\n",
    "print(X_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d2156-2606-422b-ba31-8e84a6f4a954",
   "metadata": {},
   "source": [
    "【例4.6】L2正则化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f65e54-c541-4451-9d62-4143b60e7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "transformer = Normalizer(norm='l2')\n",
    "X_normalized = transformer.transform(X)\n",
    "\n",
    "print(X_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec97aa0b-a623-4f2c-a2ad-331aea20b092",
   "metadata": {},
   "source": [
    "【例4.7】将['apple', 'banana', 'pear']进行LabelEncoder。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35c9ae-fda5-4598-bc98-abd62220bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 创建 LabelEncoder 对象\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 定义标签列表\n",
    "labels = ['apple', 'banana', 'pear']\n",
    "\n",
    "# 使用 LabelEncoder 对标签进行编码\n",
    "encoded_labels = le.fit_transform(labels)\n",
    "# 输出编码结果\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b8081-1518-4037-8022-2c65f65a7ba8",
   "metadata": {},
   "source": [
    "【例4.8】使用scikit-learn将[“红色”，“蓝色”，“绿色”]进行OneHotEncoder编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc971ef6-5978-475f-8a81-05355ee217af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "# 创建 OneHotEncoder 对象\n",
    "ohe = OneHotEncoder()\n",
    "# 定义标签列表\n",
    "labels = ['红色', '蓝色', '绿色']\n",
    "# 使用 OneHotEncoder 对标签进行独热编码\n",
    "encoded_labels = ohe.fit_transform(np.array(labels).reshape(-1, 1)).toarray()\n",
    "# 输出独热编码结果\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e5dd4a-5440-49d7-b623-2e20cc5fa427",
   "metadata": {},
   "source": [
    "【例4.9】使用scikit-learn将文本分成单个单词（称为标记），并计算每个标记在文本中出现的频率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16735e2-82aa-46a6-8051-55e06b8beb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "# 创建 CountVectorizer 对象，并拟合文本数据\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "# 转换文本数据\n",
    "vectorized_corpus = vectorizer.transform(corpus)\n",
    "# 将稀疏矩阵转换为密集矩阵并打印结果\n",
    "print(vectorized_corpus.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408d863-7eee-44e1-9e72-f18624facb88",
   "metadata": {},
   "source": [
    "【例4.10】使用TF-IDF对字符串进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9444b-0da0-4347-b02f-94f3872d3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'That is also a book!!']\n",
    "#创建 TfidfVectorizer 对象，并拟合文本数据\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "#转换文本数据\n",
    "vectorized_corpus = vectorizer.transform(corpus)\n",
    "print(vectorized_corpus)\n",
    "#将稀疏矩阵转换为密集矩阵并打印结果\n",
    "print(vectorized_corpus.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d208a032-c372-4e1d-a14c-421ffc56cf02",
   "metadata": {},
   "source": [
    "【例4.11】下面是一个简单的示例代码，演示如何使用VarianceThreshold方法对数据集进行特征选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d8051-9375-48bd-a8cc-11ea2b737501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 方差选择法，删除方差低于阈值的特征\n",
    "selector = VarianceThreshold(threshold=0.2)\n",
    "X_new = selector.fit_transform(X)\n",
    "\n",
    "# 输出选择后的数据集大小\n",
    "print(f\"原始数据集大小：{X.shape}, 特征选择后的数据集大小：{X_new.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591307c-08d2-4b18-8d82-6b40686316a7",
   "metadata": {},
   "source": [
    "【例4.12】卡方检验对数据集属性选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b222969-a03c-4a5d-87ab-4b3eac56ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 使用 SelectKBest 方法和卡方检验选择最重要的两个特征\n",
    "selector = SelectKBest(chi2, k=2)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(selector.get_support())\n",
    "# 打印选择的特征的值\n",
    "print(X_new[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5310ac-b5fb-4cb7-85ec-7238953ac134",
   "metadata": {},
   "source": [
    "【例4.13】相关系数对数据集属性选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82822c-7cc7-4d37-849d-175fc7145579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# 加载乳腺癌数据集\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# 使用 SelectKBest 方法和相关系数选择与分类目标相关性最高的两个特征\n",
    "selector = SelectKBest(f_regression, k=3)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(selector.get_support())\n",
    "# 打印选择的特征的值\n",
    "print(X_new[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220277d9-8241-4ec7-8279-b35ce559f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# 使用 SelectKBest 方法和相关系数选择与分类目标相关性最高的两个特征\n",
    "print(X[:5])\n",
    "selector = SelectKBest(f_regression, k=3)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(selector.get_support())\n",
    "# 打印选择的特征的值\n",
    "print(X_new[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b0b342-8f5e-4ef0-9417-f68e29bfedbd",
   "metadata": {},
   "source": [
    "【例4.14】Wrapper方法对数据集属性选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85098f38-643b-4ff8-864e-ae4ea13b6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# 使用 SelectKBest 方法和相关系数选择与分类目标相关性最高的两个特征\n",
    "print(X[:5])\n",
    "\n",
    "# 定义线性回归模型\n",
    "model = LinearRegression()\n",
    "\n",
    "# 使用 RFECV 方法选择最佳特征子集\n",
    "selector = RFECV(model, step=1, cv=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# 打印选择的特征的数量\n",
    "print(selector.n_features_)\n",
    "# 打印选择的特征的编号\n",
    "print(selector.support_)\n",
    "# 打印选择的特征的名称\n",
    "# 打印选择的特征的名称\n",
    "selected_feature_names = [name for name, selected in zip(iris.feature_names, selector.support_) if selected]\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86bd87-758d-49fe-b1d9-ce9227725ec8",
   "metadata": {},
   "source": [
    "【例4.15】使用 Lasso Regression 进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590415a4-bd99-4186-ba27-e69163d7cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# 加载波士顿房价数据集\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "# 定义 Lasso 回归模型\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# 使用 Lasso 方法选择最佳特征子集\n",
    "model.fit(X, y)\n",
    "selector = model.coef_ != 0\n",
    "\n",
    "# 打印选择的特征的数量\n",
    "print(sum(selector))\n",
    "# 打印选择的特征的名称\n",
    "print(boston.feature_names[selector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9c918-3ed0-454f-983f-d268913752a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# 加载糖尿病数据集\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# 定义 Lasso 回归模型\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# 使用 Lasso 方法选择最佳特征子集\n",
    "model.fit(X, y)\n",
    "selector = model.coef_ != 0\n",
    "\n",
    "# 打印选择的特征的数量\n",
    "\n",
    "# 打印选择的特征的名称\n",
    "print(diabetes.feature_names,f'共有{len(diabetes.feature_names)}')\n",
    "print('从中选择:',sum(selector))\n",
    "selected_feature_names = [name for name, selected in zip(diabetes.feature_names, selector) if selected]\n",
    "print('结果:',selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e07b82-6cdf-41e6-94b8-d4a0c60c02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Load the diabetes dataset as an alternative to load_boston\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Define a decision tree regression model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Use the decision tree method to select the best feature subset\n",
    "model.fit(X, y)\n",
    "selector = model.feature_importances_ > 0.1\n",
    "\n",
    "# Print the number of selected features\n",
    "print(sum(selector))\n",
    "# Print the names of the selected features\n",
    "selected_feature_names = [name for name, selected in zip(diabetes.feature_names, selector) if selected]\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfdcec-74b6-47b9-84b3-a30a031d6bd9",
   "metadata": {},
   "source": [
    "【例4.17】使用 PCA进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0760b30-30a6-448d-b0eb-b21042e571c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)\n",
    "# 使用PCA进行特征选择\n",
    "pca = PCA(n_components=2)\n",
    "X_new = pca.fit_transform(X)\n",
    "\n",
    "# 打印新数据的形状\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856cacc5-cdf6-4ac9-954d-66d562b1c4b1",
   "metadata": {},
   "source": [
    "【例4.17】使用Kernel PCA进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ebe3a-8ec9-4dd3-b9b2-0cfa4c254e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# 生成随机数据集\n",
    "X, y = make_circles(n_samples=1000, random_state=42, noise=0.1, factor=0.5)\n",
    "\n",
    "# 使用 Kernel PCA 方法进行特征选择\n",
    "kpca = KernelPCA(kernel='rbf', n_components=1)\n",
    "X_new = kpca.fit_transform(X)\n",
    "\n",
    "# 打印选择的特征\n",
    "print(X_new[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32921e10-dd6c-4cb7-bd40-c9efe0b906d0",
   "metadata": {},
   "source": [
    "【例4.19】使用LDA进行特征选择的示例代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a7da6-47bc-4586-a169-b54706bd67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 加载 iris 数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 定义 LDA 模型\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "# 使用 LDA 进行降维\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# 打印降维后的数据形状\n",
    "print(X.shape,X_lda.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fc991-22a2-4b0f-be0b-058cd9e71047",
   "metadata": {},
   "source": [
    "【例4.19】使用t-SNE进行特征选择的示例代码。\n",
    "下面是使用t-SNE进行特征选择的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e8998-834c-4309-b78c-735ae77acef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 使用TSNE进行特征选择\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# 打印降维后的数据\n",
    "print(X_tsne[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348820d-adb5-4720-99f1-8d410f378ccd",
   "metadata": {},
   "source": [
    "【例4.20】Isomap计算案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452aae3-3ec8-4dc6-8fd9-bc6efd46abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "# 加载 digits 数据集\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# 定义 Isomap 模型\n",
    "isomap = Isomap(n_components=2, n_neighbors=10)\n",
    "\n",
    "# 使用 Isomap 进行降维\n",
    "X_isomap = isomap.fit_transform(X)\n",
    "\n",
    "# 打印降维后的数据形状\n",
    "print(X_isomap.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89da5d-455f-4141-91f4-6306127404b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
