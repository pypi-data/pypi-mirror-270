version: '3.8'

services:
  ezlocalai:
    build: 
      context: .
      dockerfile: cuda.Dockerfile
    environment:
      - EZLOCALAI_URL=${EZLOCALAI_URL-http://localhost:8091}
      - EZLOCALAI_API_KEY=${EZLOCALAI_API_KEY-}
      - GPU_LAYERS=${GPU_LAYERS-0}
      - MAIN_GPU=${MAIN_GPU-0}
      - DEFAULT_MODEL=${DEFAULT_MODEL-TheBloke/phi-2-dpo-GGUF}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS-0}
      - WHISPER_MODEL=${WHISPER_MODEL-base.en}
      - IMG_ENABLED=${IMG_ENABLED-false}
      - SD_MODEL=${SD_MODEL-stabilityai/sdxl-turbo}
      - VISION_MODEL=${VISION_MODEL-deepseek-ai/deepseek-vl-1.3b-chat}
      - CUDA_DOCKER_ARCH=all
    restart: unless-stopped
    ports:
      - "8091:8091"
      - "8502:8501"
    volumes:
      - ./models:/app/models
      - ./outputs:/app/outputs
      - ./voices:/app/voices
      - ./whispercpp:/app/whispercpp
      - ./xttsv2_2.0.2:/app/xttsv2_2.0.2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
