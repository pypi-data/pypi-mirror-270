name: ChatRailsDB
description: A sequential flow that calls a safeguard flow and then a chatbot flow.         The
  safeguard flow checks for prompt injections.
_target_: ChatQueryDBwithPIGuardFlowModule.ChatQueryDBwithPIGuard.ChatQueryDBwithPIGuard.instantiate_from_default_config
input_interface: question
output_interface: answer
subflows_config:
  Safeguard:
    user_id: local
    name: Proxy of PromptInjectionDetectorFlow.
    flow_endpoint: PromptInjectionDetectorFlow
    description: A proxy flow that checks for prompt injections.
  DB:
    name: DB
    description: Database flow
    paths_to_data:
    - ./data/paul_graham_essay.txt
    persist_directory: data/db/demo_db_dir2
    flow_endpoint: ChromaDBFlow
    user_id: local
    chunk_size: 250
    separator: .
    similarity_search_kwargs:
      k: 1
    backend:
      api_infos: ???
  ChatBot:
    user_id: local
    flow_endpoint: ChatAtomicFlow
    name: Proxy of Chat Flow
    backend:
      api_infos: ???
      model_name:
        openai: gpt-4
    input_interface:
    - question
    - memory
    input_interface_non_initialized:
    - question
    - memory
    description: A proxy flow that calls an LLM model to generate a response, if the
      prompt is valid (no injection).
    system_message_prompt_template:
      template: 'You are a helpful chatbot that truthfully answers questions only
        related to information extracted from your Memory (this will be passed to
        you in the prompt).                     If the question is not related to
        what you extracted from memory then simply reply with the following: ''This
        question is not valid. I cannot answer it.'''
    init_human_message_prompt_template:
      template: "Question: {{question}} \n\n Memory: {{memory}}"
      input_variables:
      - question
      - memory
    human_message_prompt_template:
      template: "Question: {{question}} \n\n Memory: {{memory}}"
      input_variables:
      - question
      - memory
    previous_messages:
      first_k: 1
      last_k: 1
