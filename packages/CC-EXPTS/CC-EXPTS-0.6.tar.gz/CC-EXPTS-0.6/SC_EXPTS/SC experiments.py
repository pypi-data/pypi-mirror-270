# -*- coding: utf-8 -*-
"""SC experiments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gr_dfUCz2yoh2tIVwSzs4_RwN63Ht5eF

### **Exp 1: Implement Fuzzy Relations. (MaxMin Composition)**
"""

m1 = [[0.7, 0.6], [0.8, 0.3]]
m2 = [[0.8, 0.5, 0.4], [0.1, 0.6, 0.7]]

result = [[max(min(m1[i][0], m2[0][j]), min(m1[i][1], m2[1][j])) for j in range(len(m2[0]))] for i in range(len(m1))]

for i in result:
    print(i)

"""### **Exp 2: Implementation of McCulloch-Pitts Model**"""

class McCullochPittsNeuron:
    def __init__(self, weights, threshold):
        self.weights = weights
        self.threshold = threshold

    def activate(self, inputs):
        return sum(inputs) >= self.threshold

if __name__ == "__main__":
    neuron = McCullochPittsNeuron([1, 1], 1.0)

    inputs = [
        ([1, 1], sum([1, 1])),
        ([0, 1], sum([0, 1])),
        ([1, 0], sum([1, 0])),
        ([0, 0], sum([0, 0]))
    ]

    for input_data, sum_value in inputs:
        output = neuron.activate(input_data)
        print(f"Input {input_data}: Sum {sum_value} Output {output}")

"""### **Exp 3: Implement Single Layer Perceptron Learning Algorithm**"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import Perceptron
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)

perceptron = Perceptron().fit(X_train, y_train)
y_pred = perceptron.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Learned Weights:", perceptron.coef_)
print("Learned Bias:", perceptron.intercept_)

"""### **Exp 4: Write a Program for Error Back Propagation Algorithms**"""

import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

def backpropagation(X, y, num_epochs, learning_rate):
    np.random.seed(1)
    weights_1 = 2 * np.random.random((3, 4)) - 1
    weights_2 = 2 * np.random.random((4, 1)) - 1

    for _ in range(num_epochs):
        layer_1 = sigmoid(np.dot(X, weights_1))
        layer_2 = sigmoid(np.dot(layer_1, weights_2))

        error = y - layer_2
        delta_2 = error * sigmoid_derivative(layer_2)
        delta_1 = delta_2.dot(weights_2.T) * sigmoid_derivative(layer_1)

        weights_2 += learning_rate * layer_1.T.dot(delta_2)
        weights_1 += learning_rate * X.T.dot(delta_1)

    return layer_2

X = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
y = np.array([[0], [1], [1], [0]])
num_epochs = 10000
learning_rate = 0.1

output = backpropagation(X, y, num_epochs, learning_rate)
print(output)

"""### **Exp 5: Write a program to implement RNN**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, SimpleRNN

# Generate synthetic dataset
N, Tp = 1000, 800
t = np.arange(0, N)
x = np.sin(0.02 * t) + 2 * np.random.rand(N)
df = pd.DataFrame(x)

# Prepare the dataset
values = df.values
train, test = values[:Tp], values[Tp:]

# Add step elements into train and test
step = 4
test = np.append(test, np.repeat(test[-1], step))
train = np.append(train, np.repeat(train[-1], step))

# Convert into dataset matrix
def convertToMatrix(data, step):
    X, Y = [], []
    for i in range(len(data) - step):
        d = i + step
        X.append(data[i:d])
        Y.append(data[d])
    return np.array(X), np.array(Y)

trainX, trainY = convertToMatrix(train, step)
testX, testY = convertToMatrix(test, step)

# Reshape the data
trainX, testX = trainX.reshape(-1, 1, step), testX.reshape(-1, 1, step)

# Build the RNN model
model = Sequential([
    SimpleRNN(units=32, input_shape=(1, step), activation="relu"),
    Dense(8, activation="relu"),
    Dense(1)
])
model.compile(loss='mean_squared_error', optimizer='rmsprop')

# Train the model
model.fit(trainX, trainY, epochs=100, batch_size=16, verbose=2)

# Make predictions
trainPredict, testPredict = model.predict(trainX), model.predict(testX)
predicted = np.concatenate((trainPredict, testPredict), axis=0)

# Plot the results with customizations
plt.figure(figsize=(10, 6))
plt.plot(df.index, df.values, label='Original Data', color='blue')
plt.plot(df.index, predicted, label='Predicted Data', color='red', linestyle='--')
plt.axvline(df.index[Tp], color='green', linestyle='--', label='Train/Test Split')
plt.title('RNN Prediction vs Original Data')
plt.xlabel('Time Steps')
plt.ylabel('Values')
plt.legend()
plt.grid(True)
plt.show()

"""### **Exp 6: Write a program for Image Classification using CNN**"""

import tensorflow as tf
from keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

# Print the shapes of the loaded data
print("Shape of training images:", train_images.shape)
print("Shape of training labels:", train_labels.shape)
print("Shape of test images:", test_images.shape)
print("Shape of test labels:", test_labels.shape)

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

# Flatten the output from 2D to 1D
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))  # 10 classes for CIFAR-10

# Print a summary of the model architecture
model.summary()

model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
history = model.fit(train_images, train_labels, epochs=50, validation_data=(test_images, test_labels))

test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print('Test accuracy:', test_acc)

model.save('model.h5')

import numpy as np
import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow

# Load the trained model
model = tf.keras.models.load_model('model.h5')

# Load and preprocess a test image
image_path = '/content/drive/MyDrive/Dataset/ImageSet/dog1.jpg'
image = tf.keras.preprocessing.image.load_img(image_path, target_size=(32, 32))
input_array = tf.keras.preprocessing.image.img_to_array(image)
input_array = np.expand_dims(input_array, axis=0)
input_array = input_array / 255.0

img = cv2.imread(image_path)
cv2_imshow(img)

# Make predictions
predictions = model.predict(input_array)
predicted_class = np.argmax(predictions[0])

# Print the predicted class and confidence value
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
print("Predicted class:", class_names[predicted_class])

"""### **Exp 7: Implementation of Simple Genetic Algorithm**"""

import numpy as np

# Define the fitness function
def fitness_function(solution):
    return np.sum(solution)

# Initialize population
population_size = 10
solution_length = 10
population = np.random.randint(0, 2, (population_size, solution_length))

# Main loop
for generation in range(100):
    # Calculate fitness for each solution
    fitnesses = np.array([fitness_function(sol) for sol in population])

    # Select parents
    parents = population[np.argsort(fitnesses)[-2:]]

    # Crossover
    crossover_point = np.random.randint(0, solution_length)
    child1, child2 = np.concatenate((parents[0, :crossover_point], parents[1, crossover_point:])), np.concatenate((parents[1, :crossover_point], parents[0, crossover_point:]))

    # Mutation
    mutation_rate = 0.1
    child1, child2 = np.where(np.random.rand(solution_length) < mutation_rate, 1 - child1, child1), np.where(np.random.rand(solution_length) < mutation_rate, 1 - child2, child2)

    # Replacement
    population[np.argsort(fitnesses)[-2:]] = np.array([child1, child2])

# Print the best solution
best_solution = population[np.argmax(fitnesses)]

print("Best solution:", best_solution)

"""### **Exp 8: Design a fuzzy controller**"""

import numpy as np
import skfuzzy as fuzz
from skfuzzy import control as ctrl

# Define fuzzy sets for the input (distance to obstacle) and output (speed)
distance = ctrl.Antecedent(np.arange(0, 101, 1), 'distance')
speed = ctrl.Consequent(np.arange(0, 101, 1), 'speed')

# Define fuzzy sets for distance
distance.automf(names=['close', 'medium', 'far'])

# Define fuzzy sets for speed
speed.automf(names=['slow', 'medium', 'fast'])

# Define fuzzy rules
rules = [
    ctrl.Rule(distance['close'], speed['fast']),
    ctrl.Rule(distance['medium'], speed['medium']),
    ctrl.Rule(distance['far'], speed['slow'])
]

# Create the fuzzy control system
fuzzy_ctrl = ctrl.ControlSystem(rules)
fuzzy_sim = ctrl.ControlSystemSimulation(fuzzy_ctrl)

# Example input: distance to obstacle
distance_to_obstacle = 10

# Input the distance to the fuzzy system and compute the output
fuzzy_sim.input['distance'] = distance_to_obstacle
fuzzy_sim.compute()

# Print the output speed
print(fuzzy_sim.output['speed'])